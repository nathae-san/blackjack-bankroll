{
  "histgb_params": {
    "learning_rate": 0.1,
    "max_depth": 6,
    "min_samples_leaf": 50,
    "random_state": 42
  },
  "mlp_config": {
    "hidden": [
      256,
      128
    ],
    "dropout": 0.2,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "batch_size": 4096,
    "max_epochs": 25,
    "patience": 4,
    "device": "auto"
  },
  "global_oof": {
    "histgb": {
      "mae": 0.8573741427654561,
      "rmse": 1.036305407579375,
      "r2": 0.18132651610649608
    },
    "mlp": {
      "mae": 0.8593369764611763,
      "rmse": 1.0367053032574605,
      "r2": 0.1806945650387608
    }
  }
}